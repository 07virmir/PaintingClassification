{"cells":[{"cell_type":"markdown","metadata":{"id":"irAWio-Vnud8"},"source":["First, let's use PyTorch's implementation for vision transformers."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62650,"status":"ok","timestamp":1714526395609,"user":{"displayName":"James Narayanan","userId":"01024470621303473804"},"user_tz":240},"id":"CYhQRRr5iQA3","outputId":"6c1e0043-422a-4e6b-f569-f7ad734bab1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting timm\n","  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.13.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch->timm)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 timm-0.9.16\n"]}],"source":["!pip install timm"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"G0cpL4j0XwtZ","executionInfo":{"status":"ok","timestamp":1714526401887,"user_tz":240,"elapsed":6281,"user":{"displayName":"James Narayanan","userId":"01024470621303473804"}}},"outputs":[],"source":["import timm\n","import torch\n","import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from torch import nn\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Subset\n","from torch.optim import Adam\n","from torch.nn import CrossEntropyLoss\n","from google.colab import drive\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15074,"status":"ok","timestamp":1714526416953,"user":{"displayName":"James Narayanan","userId":"01024470621303473804"},"user_tz":240},"id":"Af4R92IreibL","outputId":"eba6cb08-1b96-4a2e-e13e-475cee82a9bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":170,"status":"ok","timestamp":1714526417121,"user":{"displayName":"James Narayanan","userId":"01024470621303473804"},"user_tz":240},"id":"oy0jplzoemV_","outputId":"6672a29d-8439-45db-a216-e400b01b7307"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1Vhu7c9TtXf-INnjjgmUD94b4o35wSPWM/DL Project\n"]}],"source":["# %cd \"/content/drive/My Drive/DL Project\"\n","%cd /content/drive/MyDrive/'Georgia Tech'/'CS 7643'/'DL Project'"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"hKPoWnMmndO-","executionInfo":{"status":"ok","timestamp":1714527282802,"user_tz":240,"elapsed":141,"user":{"displayName":"James Narayanan","userId":"01024470621303473804"}}},"outputs":[],"source":["base_dir = 'code/data/original_data'"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"HGsvyJQffc3v","executionInfo":{"status":"ok","timestamp":1714527293720,"user_tz":240,"elapsed":10320,"user":{"displayName":"James Narayanan","userId":"01024470621303473804"}}},"outputs":[],"source":["# Define transformations\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # Resize images to 224x224\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalization\n","])\n","\n","# Load dataset from directory\n","dataset = datasets.ImageFolder(base_dir, transform=transform)\n","\n","# Split dataset into training and validation sets\n","train_idx, val_idx = train_test_split(np.arange(len(dataset)), test_size=0.2, random_state=42)\n","\n","# Create training and validation subsets\n","train_dataset = Subset(dataset, train_idx)\n","val_dataset = Subset(dataset, val_idx)\n","\n","# Data loaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1558,"status":"ok","timestamp":1714527295265,"user":{"displayName":"James Narayanan","userId":"01024470621303473804"},"user_tz":240},"id":"TJ_T5W1VeeaM"},"outputs":[],"source":["model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=20)\n","\n","if torch.cuda.is_available():\n","    model = model.cuda()\n","\n","# Optimizer and loss function\n","optimizer = Adam(model.parameters(), lr=0.001)\n","criterion = CrossEntropyLoss()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YBq0CPGhqDh","executionInfo":{"status":"ok","timestamp":1714529283218,"user_tz":240,"elapsed":714440,"user":{"displayName":"James Narayanan","userId":"01024470621303473804"}},"outputId":"d4725f9f-540e-4034-e971-8e388ae6dce7"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 101/101 [22:02<00:00, 13.09s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Loss: 3.3735139740969333\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 101/101 [01:12<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Loss: 2.526746186128109\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 101/101 [01:12<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Loss: 2.289847045231516\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 101/101 [01:13<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 Loss: 2.063830394886771\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 101/101 [01:14<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 Loss: 1.9586362900825591\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 101/101 [01:14<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 Loss: 1.8178379998322385\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 101/101 [01:14<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 Loss: 1.7364352158855667\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 101/101 [01:14<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 Loss: 1.7094669438117938\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 101/101 [01:14<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 Loss: 1.6831271931464378\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 101/101 [01:14<00:00,  1.36it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 Loss: 1.6334991752916586\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# Training function\n","def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for inputs, labels in tqdm(train_loader):\n","            if torch.cuda.is_available():\n","                inputs, labels = inputs.cuda(), labels.cuda()\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * inputs.size(0)\n","        print(f'Epoch {epoch+1} Loss: {running_loss / len(train_loader.dataset)}')\n","\n","# Train the model\n","train_model(model, train_loader, criterion, optimizer)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":353191,"status":"ok","timestamp":1714529636409,"user":{"displayName":"James Narayanan","userId":"01024470621303473804"},"user_tz":240},"id":"_1ti_1lrh2_p","outputId":"a720e5ad-9baa-45d5-8c5d-6ca1e66ea950"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 44.48574969021065%\n"]}],"source":["def evaluate_model(model, val_loader):\n","    model.eval()\n","    correct = total = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            if torch.cuda.is_available():\n","                inputs, labels = inputs.cuda(), labels.cuda()\n","\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    print(f'Validation Accuracy: {accuracy}%')\n","\n","# Evaluate the model\n","evaluate_model(model, val_loader)"]},{"cell_type":"markdown","metadata":{"id":"walokPQon1ES"},"source":["Next, let's test out HuggingFace's transformer implementation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGbsAGM6w_uS"},"outputs":[],"source":["# import torch\n","# import numpy as np\n","# from torchvision import datasets, transforms\n","# from torch.utils.data import DataLoader, Subset\n","# from transformers import ViTImageProcessor, ViTForImageClassification, ViTConfig\n","# from sklearn.model_selection import train_test_split\n","\n","# # Data setup\n","# dataset_path = base_dir\n","# # transform = transforms.Compose([\n","# #     transforms.Resize((224, 224)),  # Resize all images to the size expected by ViT\n","# #     transforms.ToTensor(),          # Convert images to tensors\n","# #     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the images\n","# # ])\n","# full_dataset = datasets.ImageFolder(dataset_path, transform=None)\n","\n","# # Split the dataset into training and validation\n","# train_idx, val_idx = train_test_split(np.arange(len(full_dataset)), test_size=0.2, random_state=42)\n","# train_dataset = Subset(full_dataset, train_idx)\n","# val_dataset = Subset(full_dataset, val_idx)\n","\n","# # Initialize the image processor\n","# image_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n","\n","# # Custom collate function using the image processor\n","# def collate_fn(batch):\n","#     images, labels = zip(*batch)\n","#     processed_images = torch.stack([image_processor(images=x, return_tensors=\"pt\").pixel_values.squeeze(0) for x in images])\n","#     labels = torch.tensor(labels)\n","#     return processed_images, labels\n","\n","# # Data loaders with custom collate function\n","# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n","# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQ8kXRejxFoG"},"outputs":[],"source":["# # Model setup\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# # Load the configuration from the pre-trained model\n","# config = ViTConfig.from_pretrained('google/vit-base-patch16-224', num_labels=20)\n","\n","# # Now load the pre-trained model with the updated configuration\n","# # Use `ignore_mismatched_sizes=True` to ignore the size mismatches in classifier layers\n","# model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224', config=config, ignore_mismatched_sizes=True)\n","# # Setup the model for your specific number of classes\n","# model.classifier = torch.nn.Linear(model.config.hidden_size, 20)\n","# model.num_labels = 20\n","# model.config.num_labels = 20\n","\n","# model.to(device)\n","\n","# # Optimizer\n","# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","# # Training function\n","# def train(model, train_loader, optimizer, device):\n","#     model.train()\n","#     total_loss = 0\n","#     for images, labels in train_loader:\n","#         images, labels = images.to(device), labels.to(device)\n","\n","#         optimizer.zero_grad()\n","#         outputs = model(images).logits\n","#         loss = torch.nn.functional.cross_entropy(outputs, labels)\n","#         loss.backward()\n","#         optimizer.step()\n","\n","#         total_loss += loss.item()\n","#     print(f\"Average training loss: {total_loss / len(train_loader)}\")\n","\n","# # Evaluation function\n","# def evaluate(model, val_loader, device):\n","#     model.eval()\n","#     total = 0\n","#     correct = 0\n","#     with torch.no_grad():\n","#         for images, labels in val_loader:\n","#             images, labels = images.to(device), labels.to(device)\n","#             outputs = model(images).logits\n","#             _, predicted = torch.max(outputs, 1)\n","#             total += labels.size(0)\n","#             correct += (predicted == labels).sum().item()\n","\n","#     accuracy = correct / total\n","#     print(f'Validation Accuracy: {accuracy * 100:.2f}%')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EuMUaT7YxHz-"},"outputs":[],"source":["# # Training loop without evaluation each epoch\n","# num_epochs = 10\n","# for epoch in range(num_epochs):\n","#     print(f\"Epoch {epoch+1}/{num_epochs}\")\n","#     train(model, train_loader, optimizer, device)\n","\n","# # Evaluate after training is complete\n","# print(\"Evaluating model after training...\")\n","# evaluate(model, val_loader, device)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}